[INFO 07:07:00] pymarl Running command 'my_main'
[INFO 07:07:00] pymarl Started run with ID "1"
[WARNING 07:07:00] my_main !!!!!!!!!!!CUDA Avaliable!!!!!!!!!!!!
[INFO 07:07:00] my_main Runner specified in config: parallel
[INFO 07:07:00] my_main Runner resolved in args: parallel
[INFO 07:07:00] my_main Experiment Parameters:
[INFO 07:07:00] my_main 

{   'action_selector': 'soft_policies',
    'add_value_last_step': True,
    'agent': 'rnn_ns',
    'agent_output_type': 'pi_logits',
    'batch_size': 10,
    'batch_size_run': 10,
    'buffer_cpu_only': True,
    'buffer_size': 10,
    'cg_edges': 'full',
    'cg_payoff_rank': None,
    'cg_payoffs_hidden_dim': None,
    'cg_utilities_hidden_dim': None,
    'checkpoint_path': '',
    'common_reward': False,
    'critic_type': 'pac_dcg_critic_ns',
    'duelling': False,
    'entropy_end_ratio': 0.8,
    'env': 'simcity',
    'env_args': {   'grid_size': 4,
                    'key': 'simcity_no_common',
                    'map_name': 'simcity_no_common',
                    'seed': 288586007,
                    'time_limit': 100},
    'evaluate': False,
    'final_entropy_coef': 0.01,
    'gamma': 0.99,
    'grad_norm_clip': 10,
    'hidden_dim': 64,
    'hypergroup': None,
    'initial_entropy_coef': 30.0,
    'label': 'default_label',
    'learner': 'pac_dcg_learner',
    'learner_log_interval': 1000,
    'load_step': 0,
    'local_results_path': 'results',
    'log_interval': 100,
    'lr': 0.0005,
    'mac': 'non_shared_mac',
    'mask_before_softmax': True,
    'msg_anytime': True,
    'msg_iterations': 8,
    'msg_normalized': True,
    'name': 'pac_sarsa_dcg_ns',
    'obs_agent_id': False,
    'obs_individual_obs': False,
    'obs_last_action': False,
    'optim_alpha': 0.99,
    'optim_eps': 1e-05,
    'q_nstep': 10,
    'render': False,
    'repeat_id': 1,
    'reward_scalarisation': 'sum',
    'runner': 'parallel',
    'runner_log_interval': 1000,
    'save_model': True,
    'save_model_interval': 1000,
    'save_replay': False,
    'seed': 288586007,
    'standardise_rewards': False,
    'state_value_type': 'cv_critic_ns',
    't_max': 500500,
    'target_update_interval_or_tau': 0.01,
    'test_greedy': True,
    'test_interval': 100,
    'test_nepisode': 100,
    'use_cuda': True,
    'use_rnn': False,
    'use_tensorboard': True,
    'use_wandb': False,
    'wandb_mode': 'offline',
    'wandb_project': None,
    'wandb_save_model': False,
    'wandb_team': None}

[INFO 07:07:00] my_main *******************
[INFO 07:07:00] my_main Tensorboard logging dir:
[INFO 07:07:00] my_main /workspace/home/user/Documents/Github/6.S890_Course_Project/results/tb_logs/pac_sarsa_dcg_ns_seed288586007_simcity_no_common_2024-12-11 07:07:00.368586
[INFO 07:07:00] my_main *******************
[INFO 07:07:00] my_main Final parsed config: {'runner': 'parallel', 'mac': 'non_shared_mac', 'env': 'simcity', 'common_reward': False, 'reward_scalarisation': 'sum', 'env_args': {'key': 'simcity_no_common', 'map_name': 'simcity_no_common', 'seed': 288586007, 'time_limit': 100, 'grid_size': 4}, 'batch_size_run': 10, 'test_nepisode': 100, 'test_interval': 100, 'test_greedy': True, 'log_interval': 100, 'runner_log_interval': 1000, 'learner_log_interval': 1000, 't_max': 500500, 'use_cuda': True, 'buffer_cpu_only': True, 'use_tensorboard': True, 'use_wandb': False, 'wandb_team': None, 'wandb_project': None, 'wandb_mode': 'offline', 'wandb_save_model': False, 'save_model': True, 'save_model_interval': 1000, 'checkpoint_path': '', 'evaluate': False, 'render': False, 'load_step': 0, 'save_replay': False, 'local_results_path': 'results', 'gamma': 0.99, 'batch_size': 10, 'buffer_size': 10, 'lr': 0.0005, 'optim_alpha': 0.99, 'optim_eps': 1e-05, 'grad_norm_clip': 10, 'add_value_last_step': True, 'agent': 'rnn_ns', 'hidden_dim': 64, 'obs_agent_id': False, 'obs_last_action': False, 'repeat_id': 1, 'label': 'default_label', 'hypergroup': None, 'action_selector': 'soft_policies', 'mask_before_softmax': True, 'target_update_interval_or_tau': 0.01, 'obs_individual_obs': False, 'agent_output_type': 'pi_logits', 'learner': 'pac_dcg_learner', 'use_rnn': False, 'standardise_rewards': False, 'q_nstep': 10, 'critic_type': 'pac_dcg_critic_ns', 'state_value_type': 'cv_critic_ns', 'initial_entropy_coef': 30.0, 'final_entropy_coef': 0.01, 'entropy_end_ratio': 0.8, 'cg_edges': 'full', 'cg_utilities_hidden_dim': None, 'cg_payoffs_hidden_dim': None, 'cg_payoff_rank': None, 'duelling': False, 'msg_anytime': True, 'msg_iterations': 8, 'msg_normalized': True, 'name': 'pac_sarsa_dcg_ns', 'seed': 288586007}
[INFO 07:07:00] my_main run.py Using runner: parallel
[INFO 07:07:00] my_main Initialized runner: ParallelRunner
[INFO 07:07:07] my_main Beginning training for 500500 timesteps
