[INFO 02:07:25] pymarl Running command 'my_main'
[INFO 02:07:25] pymarl Started run with ID "67"
[INFO 02:07:25] my_main Experiment Parameters:
[INFO 02:07:25] my_main 

{   'action_selector': 'epsilon_greedy',
    'add_value_last_step': True,
    'agent': 'rnn',
    'agent_output_type': 'q',
    'batch_size': 32,
    'batch_size_run': 1,
    'buffer_cpu_only': True,
    'buffer_size': 5000,
    'checkpoint_path': '',
    'common_reward': True,
    'double_q': True,
    'env': 'simcity',
    'env_args': {   'grid_size': 4,
                    'key': 'simcity',
                    'map_name': 'simcity',
                    'seed': 98627619,
                    'time_limit': 100},
    'epsilon_anneal_time': 50000,
    'epsilon_finish': 0.05,
    'epsilon_start': 1.0,
    'evaluate': False,
    'evaluation_epsilon': 0.0,
    'gamma': 0.99,
    'grad_norm_clip': 10,
    'hidden_dim': 64,
    'hypergroup': None,
    'hypernet_embed': 64,
    'hypernet_layers': 2,
    'label': 'default_label',
    'learner': 'q_learner',
    'learner_log_interval': 1000,
    'load_step': 0,
    'local_results_path': 'results',
    'log_interval': 10000,
    'lr': 0.0005,
    'mac': 'basic_mac',
    'mixer': 'qmix',
    'mixing_embed_dim': 32,
    'name': 'qmix',
    'obs_agent_id': True,
    'obs_individual_obs': False,
    'obs_last_action': False,
    'optim_alpha': 0.99,
    'optim_eps': 1e-05,
    'render': False,
    'repeat_id': 1,
    'reward_scalarisation': 'sum',
    'runner': 'episode',
    'runner_log_interval': 1000,
    'save_model': False,
    'save_model_interval': 10,
    'save_replay': False,
    'seed': 98627619,
    'standardise_returns': False,
    'standardise_rewards': True,
    't_max': 200000,
    'target_update_interval_or_tau': 200,
    'test_greedy': True,
    'test_interval': 1000,
    'test_nepisode': 100,
    'use_cuda': True,
    'use_rnn': False,
    'use_tensorboard': False,
    'use_wandb': False,
    'wandb_mode': 'offline',
    'wandb_project': None,
    'wandb_save_model': False,
    'wandb_team': None}

[INFO 02:07:26] my_main Beginning training for 200000 timesteps
[INFO 02:07:26] my_main t_env: 12 / 200000
[INFO 02:07:26] my_main Estimated time left: 31 seconds. Time passed: 0 seconds
[INFO 02:07:55] my_main t_env: 1059 / 200000
[INFO 02:07:55] my_main Estimated time left: 1 hours, 30 minutes, 57 seconds. Time passed: 28 seconds
[INFO 02:08:25] my_main t_env: 2068 / 200000
[INFO 02:08:25] my_main Estimated time left: 1 hours, 39 minutes, 9 seconds. Time passed: 59 seconds
